
# 目的

IGetter 的目标是成为一个面向单机的监控型爬虫框架。

它能够监控用户关注的信息的改变，例如关注的微博更新，知乎回答、专栏更新等等。

大家可能用过一个APP叫即刻，它的作用与此类似。作者在两年前开始使用，感觉很棒，能把想要的信息聚合起来。不过即刻的发展方向转变为社交了，连爬虫机器人都不能创建了，稍稍有点失望。所以我写了这个爬虫框架，就是为了弥补这个遗憾。

至于为什么它是面向单机的呢，是为了避免爬虫是否违法以及版权纠纷。不过后期会考虑做成P2P的模式，以提高消息的及时性。

# 工作流程

在IGetter中Job是一个爬虫的称呼。比如`steamCN日报更新`就是一个Job。

Job只负责向Engine发出请求，然后等待Engine返回请求，接收到请求后再执行其解析过程，得到信息后进行存储。

负责执行、调度Job的就是Engine，它会根据Job的某些属性来进行决定是否执行，例如Job的`minInterval`属性决定其最小执行间隔，因为过于密集的请求会产生IP被封禁的风险。

Donwloader则负责下载Engine收到的请求，它是一个异步并发下载队列，下载完成后通知Engine交付给Job，充分利用了Node的异步特色，高效而快速。

Store负责存储，存储Job爬取到的有效信息。

Plugin用于扩展IGetter。它使用`Tapable`库将一个爬虫从发出请求到Downloader正式下载再到接收响应的整个过程都暴露出来。在此之上我们可以做很多事情，例如：在发出请求前附加Random User-Agent；在请求时进行代理设置；整个过程中收集信息进行性能分析、爬虫监控等等都交由Plugin来扩展。（得益于WebPack产生的灵感）


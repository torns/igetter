
## 目的

IGetter 的目标是成为一个面向单机的监控型爬虫框架。

它能够监控用户关注的信息的改变，例如关注的微博更新，知乎回答、专栏更新等等。

大家可能用过一个 APP 叫即刻，它的作用与此类似。作者在两年前开始使用，感觉很棒，能把想要的信息聚合起来。不过即刻的发展方向转变为社交了，连爬虫机器人都不能创建了，稍稍有点失望。所以我写了这个爬虫框架，就是为了弥补这个遗憾。

至于为什么它是面向单机的呢，是为了避免爬虫是否违法的问题以及版权纠纷。不过后期会考虑做成P2P的模式，以提高消息的及时性。

## 工作流程

在 IGetter 中 Job 是一个爬虫的称呼。比如`steamCN日报更新`就是一个 Job。

Job 只负责向 Engine 发出请求，然后等待 Engine 返回请求，接收到请求后再执行其解析过程，得到信息后交由 Engine 存储。

负责执行、调度 Job 的就是 Engine，它会根据 Job 的某些属性来进行决定是否执行、何时执行它，例如 Job 的`minInterval`属性决定其最小执行间隔，因为过于密集的请求会面临IP被封禁的风险。

Donwloader 则负责下载 Engine 收到的请求，它是一个异步并发下载队列，下载完成后通知 Engine 交付给 Job，充分利用了 Node 的异步特色，高效而快速。

Store 负责存储，存储 Job 爬取到的有效信息。

Plugin 用于扩展 IGetter。它使用`Tapable`库将一个爬虫从发出请求到 Downloader 正式下载再到接收响应的整个过程都暴露出来。在此我们可以做很多事情，例如：在发出请求前附加随机 User-Agent；在请求时进行代理设置；整个过程中收集信息进行性能分析、爬虫监控等等都交由 Plugin 来扩展。（由 WebPack 产生的灵感）
